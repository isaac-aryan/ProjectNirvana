<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Project Nirvana</title>

    <link rel="stylesheet" href="app.css">

</head>
<body>
    <h1>Project Nirvana</h1>

    <h3>Utilise the power of computer vision to bring life to your casual, involuntary air drums!</h3>

    <h3 style="color: rgb(228, 193, 248);">~ How it works: ~</h3>
    <p>Imagine your screen is divided into 4 quadrants.<br>
  
            A pointing finger detected in the top left plays a Hi Hat!<br>
            A closed fist in the bottom right plays a Bass Drum!<br>
            A pointing finger or closed fist in the top riight plays a Snare Drum!<br>
  
    </p>
    <video id="video"></video>
    <audio src="/drums/hiHat.mp3" id="audio"></audio>
    <p style="color: rgb(228, 193, 248);;">Live Model Detection Feed -> </p>
    <canvas id="canvas"></canvas>

    

    <script src="https://cdn.jsdelivr.net/npm/handtrackjs/dist/handtrack.min.js"></script>
    <script src="script.js"></script>
</body>
</html>
